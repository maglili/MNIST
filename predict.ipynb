{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predit pics\n",
    "## import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in CPU\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pylab as plt\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "IMAGE_SIZE = 28\n",
    "composed = transforms.Compose([transforms.Grayscale(num_output_channels=1), \\\n",
    "                               transforms.Resize((IMAGE_SIZE, IMAGE_SIZE), interpolation = 2), \\\n",
    "                               transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "def show_data(data_sample):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n",
    "    \n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "  print('GPU is avalible')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('Training in CPU')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "### loading model(invert)\n",
    "<a href=\"https://www.researchgate.net/figure/Architecture-of-a-Convolutional-Neural-Network-CNN-The-traditional-CNN-structure-is_fig1_330106889\"><img src=\"https://www.researchgate.net/publication/330106889/figure/fig1/AS:710963951063040@1546518423301/Architecture-of-a-Convolutional-Neural-Network-CNN-The-traditional-CNN-structure-is.png\" alt=\"Architecture of a Convolutional Neural Network (CNN). The traditional CNN structure is mainly composed of convolution layers, pooling layers, fully connected layers, and some activation functions. Each convolution kernel is connected to the part of feature maps. The input is connected to all of the output elements in the fully connected layer.\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    # Contructor\n",
    "    def __init__(self, out_1=64, out_2=128):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, stride=1, padding=2)\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(out_2 * 7 * 7, 10)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "model = CNN(out_1=64, out_2=128)\n",
    "model.load_state_dict(torch.load('invert_color.pt', map_location=device)) #<--------------------change model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1152x648 at 0x25CB6491C10>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = Image.open(r\"D:\\user\\Documents\\N26091194_TENG\\Projects\\MNIST\\pics\\77.jpg\")#<-----change your pics path\n",
    "print(image)\n",
    "X = composed(image)\n",
    "X = X[None, :, :]\n",
    "show_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推測 0 的機率: 0.00159 %\n",
      "推測 1 的機率: 96.7 %\n",
      "推測 2 的機率: 0.488 %\n",
      "推測 3 的機率: 0.00318 %\n",
      "推測 4 的機率: 0.32 %\n",
      "推測 5 的機率: 0.0546 %\n",
      "推測 6 的機率: 0.00097 %\n",
      "推測 7 的機率: 2.45 %\n",
      "推測 8 的機率: 0.000287 %\n",
      "推測 9 的機率: 0.00469 %\n",
      "----------------------------------------\n",
      "預測結果 1st : 1\n",
      "預測結果 2nd : 7\n",
      "預測結果 3rd : 2\n",
      "----------------------------------------\n",
      "預測為 : 1\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "z = model(X)\n",
    "z = nn.functional.softmax(z, dim=1)\n",
    "output = z.tolist()[0]\n",
    "output_copy = output.copy()\n",
    "\n",
    "for index, value in enumerate(output):\n",
    "    print('推測 '+str(index)+' 的機率: {:.3} %'.format(value * 100))\n",
    "print('-'*40)\n",
    "\n",
    "print('預測結果 1st :', output.index(max(output_copy)))\n",
    "output_copy.remove(max(output_copy))\n",
    "\n",
    "print('預測結果 2nd :', output.index(max(output_copy)))\n",
    "output_copy.remove(max(output_copy))\n",
    "\n",
    "print('預測結果 3rd :', output.index(max(output_copy)))\n",
    "output_copy.remove(max(output_copy))\n",
    "\n",
    "print('-'*40)\n",
    "print('預測為 :',output.index(max(output)))\n",
    "\n",
    "# model: invert_color.pt\n",
    "# error in black : 1, 3, 6, 7, 9 (acc: 50%)\n",
    "# error in white : 0, 6, 7, 9 (acc: 60%)\n",
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "### loading model\n",
    "<a href=\"https://www.researchgate.net/figure/Proposed-Modified-ResNet-18-architecture-for-Bangla-HCR-In-the-diagram-conv-stands-for_fig1_323063171\"><img src=\"https://www.researchgate.net/profile/Muhammad_Hasan19/publication/323063171/figure/fig1/AS:603178554904576@1520820382219/Proposed-Modified-ResNet-18-architecture-for-Bangla-HCR-In-the-diagram-conv-stands-for.png\" alt=\"Proposed Modified ResNet-18 architecture for Bangla HCR. In the diagram, conv stands for Convolutional layer, Pool stands for MaxPool layer, batch norm stand for batch normalization, Relu stands for rectified linear unit activation layer, Sum stands for the addition in ResNet, and FC stand for fully connected hidden layers. In this architecture, we have eight ResNet modules which are modified by adding a dropout layer after the second convolutional layers.\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models.resnet import ResNet, BasicBlock, Bottleneck\n",
    "\n",
    "class MNISTResNet(ResNet):\n",
    "    def __init__(self):\n",
    "        super(MNISTResNet, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=10) # Based on ResNet18\n",
    "        # super(MNISTResNet, self).__init__(BasicBlock, [3, 4, 6, 3], num_classes=10) # Based on ResNet34\n",
    "        # super(MNISTResNet, self).__init__(Bottleneck, [3, 4, 6, 3], num_classes=10) # Based on ResNet50\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3,bias=False)\n",
    "\n",
    "model = MNISTResNet()\n",
    "model.load_state_dict(torch.load('ResNet', map_location=device))  #<--------------------change model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### disply pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = Image.open(r\"D:\\user\\Documents\\N26091194_TENG\\Projects\\MNIST\\pics\\77.jpg\") #<-----change your pics path\n",
    "X = composed(image)\n",
    "X = X[None, :, :]\n",
    "show_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推測 0 的機率: 0.256 %\n",
      "推測 1 的機率: 41.5 %\n",
      "推測 2 的機率: 0.335 %\n",
      "推測 3 的機率: 0.437 %\n",
      "推測 4 的機率: 0.387 %\n",
      "推測 5 的機率: 0.588 %\n",
      "推測 6 的機率: 0.0713 %\n",
      "推測 7 的機率: 49.0 %\n",
      "推測 8 的機率: 3.16 %\n",
      "推測 9 的機率: 4.33 %\n",
      "----------------------------------------\n",
      "預測結果 1st : 7\n",
      "預測結果 2nd : 1\n",
      "預測結果 3rd : 9\n",
      "----------------------------------------\n",
      "預測為 : 7\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "z = model(X)\n",
    "z = nn.functional.softmax(z, dim=1)\n",
    "output = z.tolist()[0]\n",
    "output_copy = output.copy()\n",
    "\n",
    "for index, value in enumerate(output):\n",
    "    print('推測 '+str(index)+' 的機率: {:.3} %'.format(value * 100))\n",
    "print('-'*40)\n",
    "\n",
    "print('預測結果 1st :', output.index(max(output_copy)))\n",
    "output_copy.remove(max(output_copy))\n",
    "\n",
    "print('預測結果 2nd :', output.index(max(output_copy)))\n",
    "output_copy.remove(max(output_copy))\n",
    "\n",
    "print('預測結果 3rd :', output.index(max(output_copy)))\n",
    "output_copy.remove(max(output_copy))\n",
    "\n",
    "print('-'*40)\n",
    "print('預測為 :',output.index(max(output)))\n",
    "# model: ResNet\n",
    "# error in black : 0, 3, 4, 5, 6, 7, 9 (acc: 30%)\n",
    "# error in white : 6 (acc: 90%)\n",
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
